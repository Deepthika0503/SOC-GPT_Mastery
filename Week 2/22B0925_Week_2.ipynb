{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNGAOAjTmBhY3DzbE8f/1n+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gV16P8yNfVbL"},"outputs":[],"source":["words = open('names.txt', 'r').read().splitlines()"]},{"cell_type":"code","source":["chars = sorted(list(set(''.join(words))))"],"metadata":{"id":"zpxCx15UjtR4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["new_chars = ['.'] + chars\n","list_twos = []\n","for ch1 in new_chars:\n","  for ch2 in new_chars[1:]:\n","    list_twos.append(ch1+ch2)\n","list_twos.append('..')\n","pairs = sorted(list_twos)\n","len(pairs)\n","# pairs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbAzsNoGmgHz","executionInfo":{"status":"ok","timestamp":1718345567693,"user_tz":-330,"elapsed":1074,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"8913d105-0c47-45a0-df59-d0703088d7bc"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["703"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["stoi_2 = {s:i for i, s in enumerate(pairs)}\n","itos_2 = {i:s for s, i in stoi_2.items()}\n","stoi_1 = {s:i for i, s in enumerate(new_chars)}\n","itos_1 = {i:s for s, i in stoi_1.items()}"],"metadata":{"id":"aa1i6kZCm2dJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Counting method for trigram model"],"metadata":{"id":"YWTR2grwnX-h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"oM_HUT6foC5u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)"],"metadata":{"id":"Epe3z32Rn9Vr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for w in words:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1"],"metadata":{"id":"8BXHgEVPoGAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["P = (N+1).float()\n","P/=P.sum(1, keepdims=True)"],"metadata":{"id":"tfxnTpjGo48E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in words:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'{nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zEqyZ2TRpMuI","executionInfo":{"status":"ok","timestamp":1718345610474,"user_tz":-330,"elapsed":2763,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"f1656b98-af30-4692-9b82-2139c49ee07b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2119739055633545\n"]}]},{"cell_type":"code","source":["# Counting method for bigram model"],"metadata":{"id":"JvZf-ptap9H9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Nb = torch.zeros((27, 27), dtype = torch.int32)"],"metadata":{"id":"X8vkATAQs7TB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for w in words:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(ch2, ch2[1:]):\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    Nb[indx1, indx2] += 1"],"metadata":{"id":"eYF4NUUAtD-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Pb = (Nb+1).float()\n","Pb/=Pb.sum(1, keepdims=True)"],"metadata":{"id":"OQSatjdxtYK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in words:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(chs, chs[1:]):\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    prob = Pb[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'{nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4CQogm1tdnp","executionInfo":{"status":"ok","timestamp":1718345620681,"user_tz":-330,"elapsed":3101,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"1637b3d6-4a08-4013-e423-a5c941684aae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3.2960469722747803\n"]}]},{"cell_type":"markdown","source":["**Observe that the loss in case of trigram model (2.21..) is less than the loss in case of the bigram model (3.29..)**"],"metadata":{"id":"MKousiVcJKp_"}},{"cell_type":"code","source":["# Counting method of trigram with train, dev and test sets"],"metadata":{"id":"dtHmliR-uIZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","random.seed(42)\n","random.shuffle(words)\n","n1 = int(0.8*len(words))\n","n2 = int(0.9*len(words))\n","\n","train_set = words[:n1]\n","dev_set = words[n1:n2]\n","test_set = words[n2:]"],"metadata":{"id":"-VAOlATCuYVD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)"],"metadata":{"id":"lA_oZEAiuRQO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1"],"metadata":{"id":"Gh25u3ZXuUX-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["P = (N+1).float()\n","P/=P.sum(1, keepdims=True)"],"metadata":{"id":"YB6EHDWEu0Fp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zptOorq6aRbM","executionInfo":{"status":"ok","timestamp":1718346141636,"user_tz":-330,"elapsed":2611,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"38c5f4c7-8ef9-4423-e173-68d84e56155b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.2157092094421387\n"]}]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0KPIPsfLu4hJ","executionInfo":{"status":"ok","timestamp":1718346141637,"user_tz":-330,"elapsed":8,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"fd867090-0599-466b-a41c-339a3a348990"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dev set loss: 2.236459732055664\n"]}]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in test_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'test set loss {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JfRwnpwJvF_G","executionInfo":{"status":"ok","timestamp":1718346142054,"user_tz":-330,"elapsed":424,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"16912b36-cf97-4838-d5ab-188c65e6669d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test set loss 2.2373220920562744\n"]}]},{"cell_type":"code","source":["# Counting method of bigram with train, dev and test sets"],"metadata":{"id":"QKMNiMCHvKXB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Nb = torch.zeros((27, 27), dtype = torch.int32)"],"metadata":{"id":"2ALV9s1qvS9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for w in train_set:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(ch2, ch2[1:]):\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    Nb[indx1, indx2] += 1"],"metadata":{"id":"UYns5m8IvYpy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Pb = (Nb+1).float()\n","Pb/=Pb.sum(1, keepdims=True)"],"metadata":{"id":"veKhZ0kivb2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3Td83luZ9nu","executionInfo":{"status":"ok","timestamp":1718346058356,"user_tz":-330,"elapsed":2313,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"8da012ea-328b-444f-8d35-b5ca6d5f6bcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.2157092094421387\n"]}]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(chs, chs[1:]):\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    prob = Pb[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sva5N2V_vfDD","executionInfo":{"status":"ok","timestamp":1718346059207,"user_tz":-330,"elapsed":421,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"85b365a8-6a7f-4fc4-dfea-9c42035f4e8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dev set loss 3.296229362487793\n"]}]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in test_set:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(chs, chs[1:]):\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    prob = Pb[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'test set loss {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dy7xr9lXvpP8","executionInfo":{"status":"ok","timestamp":1718346059622,"user_tz":-330,"elapsed":417,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"ba9f3b7b-81b5-4d48-e02b-d7aeead4af01"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test set loss 3.2962353229522705\n"]}]},{"cell_type":"markdown","source":["**Observing that the train_set loss and dev or test set losses does not differ much we can say that the model has not overfitted.**\n"],"metadata":{"id":"2Wxbpp2nagFI"}},{"cell_type":"code","source":["# Smoothing on trigram model"],"metadata":{"id":"aoe-dkStvvNM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1\n","\n","P = (N+1).float()\n","# P = (N+10).float()\n","# P = (N+100).float()\n","P/=P.sum(1, keepdims=True)\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zy4qbQgiwmzl","executionInfo":{"status":"ok","timestamp":1718346452123,"user_tz":-330,"elapsed":7035,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"343a1c07-225b-47e9-99af-4d80fdb86315"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.2157092094421387\n","dev set loss: 2.236459732055664\n"]}]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1\n","\n","# P = (N+1).float()\n","P = (N+10).float()\n","# P = (N+100).float()\n","P/=P.sum(1, keepdims=True)\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g8LIlQbraoLK","executionInfo":{"status":"ok","timestamp":1718346302074,"user_tz":-330,"elapsed":6345,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"836d4c5d-5bec-484f-8e06-106df3fa798f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.356320381164551\n","dev set loss: 2.363665819168091\n"]}]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1\n","\n","# P = (N+1).float()\n","# P = (N+10).float()\n","P = (N+100).float()\n","P/=P.sum(1, keepdims=True)\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFxZRX5xaqX7","executionInfo":{"status":"ok","timestamp":1718346314345,"user_tz":-330,"elapsed":6660,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"e29158c1-2ddc-44ac-9fe6-235d29aec5b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.7453043460845947\n","dev set loss: 2.746373176574707\n"]}]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1\n","\n","# P = (N+1).float()\n","# P = (N+10).float()\n","# P = (N+100).float()\n","P = (N+1000).float()\n","P/=P.sum(1, keepdims=True)\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KziTRnIkatd4","executionInfo":{"status":"ok","timestamp":1718346322915,"user_tz":-330,"elapsed":6694,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"b6b25bde-53a9-472c-9770-a157f09e4b3a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 3.1363141536712646\n","dev set loss: 3.1366119384765625\n"]}]},{"cell_type":"markdown","source":["**Observe that the train set loss and dev set loss are increasing as the value used for smoothing is increased. So the best setting value is 1 i.e., P = (N+1).float().**"],"metadata":{"id":"8nczZJLnbDX3"}},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1\n","\n","P = (N+1).float()\n","# P = (N+10).float()\n","# P = (N+100).float()\n","P/=P.sum(1, keepdims=True)\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in train_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'train set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in dev_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'dev set loss: {nll/n}')\n","\n","log_likelihood = 0.0\n","n = 0\n","\n","for w in test_set:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'test set loss: {nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGcBI5drxvWQ","executionInfo":{"status":"ok","timestamp":1718346492155,"user_tz":-330,"elapsed":6596,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"f20c5ead-8587-4681-9047-2812f9310461"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train set loss: 2.2157092094421387\n","dev set loss: 2.236459732055664\n","test set loss: 2.2373220920562744\n"]}]},{"cell_type":"code","source":["g = torch.Generator().manual_seed(2147483647)\n","W = torch.randn((27, 27), generator=g, requires_grad=True)"],"metadata":{"id":"0eaAdm_wx3Eo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xs, ys = [], []\n","\n","for w in words:\n","    # print(w)\n","    chs = ['.'] + list(w) + ['.']\n","    for ch1, ch2 in zip(chs, chs[1:]):\n","        indx1 = stoi_1[ch1]\n","        indx2 = stoi_1[ch2]\n","        xs.append(indx1)\n","        ys.append(indx2)\n","\n","xs = torch.tensor(xs)\n","ys = torch.tensor(ys)"],"metadata":{"id":"3oN1lM4tceOc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gf_pWl4ac9Ip","executionInfo":{"status":"ok","timestamp":1718347077853,"user_tz":-330,"elapsed":435,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"77a7db3a-d604-480b-8440-4f3bfbd1c576"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0,  5, 13,  ..., 25, 26, 24])"]},"metadata":{},"execution_count":64}]},{"cell_type":"markdown","source":["**We can directly index the indices of the which we need from W into W i.e., multiplying one hot encoded vector of index 0 is same as indexing 0 into W.**"],"metadata":{"id":"WetXwPGxepO3"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","temp = torch.tensor([0])\n","enc_temp = F.one_hot(temp, num_classes=27).float()\n","print(enc_temp @ W)\n","print(W[temp])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ErTL1xxfaQK","executionInfo":{"status":"ok","timestamp":1718347606152,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"3d231105-aa4d-4c5b-a0ca-fb1fa851c4b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 1.5674, -0.2373, -0.0274, -1.1008,  0.2859, -0.0296, -1.5471,  0.6049,\n","          0.0791,  0.9046, -0.4713,  0.7868, -0.3284, -0.4330,  1.3729,  2.9334,\n","          1.5618, -1.6261,  0.6772, -0.8404,  0.9849, -0.1484, -1.4795,  0.4483,\n","         -0.0707,  2.4968,  2.4448]], grad_fn=<MmBackward0>)\n","tensor([[ 1.5674, -0.2373, -0.0274, -1.1008,  0.2859, -0.0296, -1.5471,  0.6049,\n","          0.0791,  0.9046, -0.4713,  0.7868, -0.3284, -0.4330,  1.3729,  2.9334,\n","          1.5618, -1.6261,  0.6772, -0.8404,  0.9849, -0.1484, -1.4795,  0.4483,\n","         -0.0707,  2.4968,  2.4448]], grad_fn=<IndexBackward0>)\n"]}]},{"cell_type":"code","source":["W[xs]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UVmSqEpRc_6W","executionInfo":{"status":"ok","timestamp":1718347643646,"user_tz":-330,"elapsed":416,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"76a26700-102a-4e4e-fb4d-9b3f4828ea50"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.5674, -0.2373, -0.0274,  ..., -0.0707,  2.4968,  2.4448],\n","        [ 0.4724,  1.4830,  0.3175,  ..., -0.4275, -2.1259,  0.9604],\n","        [ 0.1936,  1.0532,  0.6339,  ...,  1.5447,  0.6006, -0.7091],\n","        ...,\n","        [ 0.7414, -0.5879, -0.4651,  ..., -0.1388,  1.3096, -0.2580],\n","        [ 1.0669,  0.2136, -0.7660,  ...,  1.3405, -0.2175,  0.8627],\n","        [ 0.2163, -0.7873, -0.3301,  ..., -0.2630, -0.7552,  0.8191]],\n","       grad_fn=<IndexBackward0>)"]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["enc = F.one_hot(xs, num_classes=27).float()"],"metadata":{"id":"le_0CR4ed8YF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["enc @ W"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jv5GC5SgeC26","executionInfo":{"status":"ok","timestamp":1718347647900,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"ae03e80d-9765-4352-a4ac-13de7aae1e2d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 1.5674, -0.2373, -0.0274,  ..., -0.0707,  2.4968,  2.4448],\n","        [ 0.4724,  1.4830,  0.3175,  ..., -0.4275, -2.1259,  0.9604],\n","        [ 0.1936,  1.0532,  0.6339,  ...,  1.5447,  0.6006, -0.7091],\n","        ...,\n","        [ 0.7414, -0.5879, -0.4651,  ..., -0.1388,  1.3096, -0.2580],\n","        [ 1.0669,  0.2136, -0.7660,  ...,  1.3405, -0.2175,  0.8627],\n","        [ 0.2163, -0.7873, -0.3301,  ..., -0.2630, -0.7552,  0.8191]],\n","       grad_fn=<MmBackward0>)"]},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["enc @ W == W[xs]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CoKq45LeLMS","executionInfo":{"status":"ok","timestamp":1718347665489,"user_tz":-330,"elapsed":3,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"1be79c49-9ca2-47d7-b2f2-a28203c998a1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        ...,\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True],\n","        [True, True, True,  ..., True, True, True]])"]},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["xs, ys = [], []\n","N = torch.zeros((27, 27), dtype = torch.int32)\n","\n","for w in words:\n","    # print(w)\n","    chs = ['.'] + list(w) + ['.']\n","    for ch1, ch2 in zip(chs, chs[1:]):\n","        indx1 = stoi_1[ch1]\n","        indx2 = stoi_1[ch2]\n","        N[indx1, indx2] += 1\n","        xs.append(indx1)\n","        ys.append(indx2)\n","\n","xs = torch.tensor(xs)\n","ys = torch.tensor(ys)"],"metadata":{"id":"2_yx_3awgIjp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["P = (N+1).float()\n","P /= P.sum(1, keepdims=True)"],"metadata":{"id":"6vyj7XQ-hEt9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logits = P[xs].log()\n","logits"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m9n8hVbmhK2L","executionInfo":{"status":"ok","timestamp":1718348810956,"user_tz":-330,"elapsed":756,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"cb8effb8-db67-4472-b660-50d6e75f20c4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-10.3754,  -1.9835,  -3.1999,  ...,  -5.4701,  -4.0912,  -3.5402],\n","        [ -1.6357,  -3.4036,  -5.1217,  ...,  -5.0354,  -2.9494,  -4.7217],\n","        [ -2.5572,  -0.9454,  -4.0778,  ...,  -8.8052,  -3.1423,  -6.3203],\n","        ...,\n","        [ -1.5855,  -1.5200,  -5.8582,  ...,  -5.8231,  -6.0124,  -4.8210],\n","        [ -2.7122,  -1.0355,  -6.1841,  ...,  -7.1004,  -2.7964,  -3.9649],\n","        [ -1.4788,  -1.9404,  -5.8916,  ...,  -2.9212,  -3.1508,  -3.5891]])"]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["loss = F.cross_entropy(logits, ys)\n","loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zxN9UqX1hlI1","executionInfo":{"status":"ok","timestamp":1718348814170,"user_tz":-330,"elapsed":829,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"3fe707ed-05ca-4ec1-cf15-5f67a5853f1d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.4546)"]},"metadata":{},"execution_count":94}]},{"cell_type":"code","source":["log_likelihoods = []\n","\n","for w in words:\n","  chs = ['.'] + list(w) + ['.']\n","  for ch1, ch2 in zip(chs, chs[1:]):\n","    # print(xs, ys)\n","    indx1 = stoi_1[ch1]\n","    indx2 = stoi_1[ch2]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihoods.append(logprob)\n","\n","logs = torch.tensor(log_likelihoods)\n","print(f'test set loss: {-logs.mean():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ceew476php5-","executionInfo":{"status":"ok","timestamp":1718349153615,"user_tz":-330,"elapsed":5384,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"3e564f16-90be-4001-ea0d-3264e58ecd12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["test set loss: 2.4546\n"]}]},{"cell_type":"markdown","source":["**Clearly the loss obtained by calculating negative log likelihoods is same as the loss obtained by using cross_entropy.**"],"metadata":{"id":"Pg37x043l2Cr"}},{"cell_type":"code","source":["logits = torch.tensor([-5, 0, 3, 100])\n","counts = logits.exp()\n","probs = counts/counts.sum()\n","probs"],"metadata":{"id":"hjX2ww9ptXpk","executionInfo":{"status":"ok","timestamp":1718353934421,"user_tz":-330,"elapsed":7,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f20863d5-b48a-44bc-e861-111a5465a1b9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 0., 0., nan])"]},"metadata":{},"execution_count":118}]},{"cell_type":"markdown","source":["**While cross_entropy function substracts the maximum value of the logits and calculates the probabilities which does not allow the probabilies to become nan**"],"metadata":{"id":"45IWONOP4Rnz"}},{"cell_type":"code","source":["logits = torch.tensor([-5, 0, 3, 5])\n","counts = logits.exp()\n","probs = counts/counts.sum()\n","probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2pVX3nsv5dYr","executionInfo":{"status":"ok","timestamp":1718354444387,"user_tz":-330,"elapsed":10,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"47b9fbbd-24da-4a5f-8c64-a1003fd8a83a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3.9751e-05, 5.8995e-03, 1.1849e-01, 8.7557e-01])"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["logits = torch.tensor([-5, 0, 3, 5]) - 5\n","counts = logits.exp()\n","probs = counts/counts.sum()\n","probs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9yVfmoMj5800","executionInfo":{"status":"ok","timestamp":1718354456100,"user_tz":-330,"elapsed":448,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"b7849673-29d7-47eb-cbf4-03567731d5d3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3.9751e-05, 5.8995e-03, 1.1849e-01, 8.7557e-01])"]},"metadata":{},"execution_count":121}]},{"cell_type":"markdown","source":["**Observe that the probabilities does not change by doing so (subtracting the maximum value).**"],"metadata":{"id":"MqAWYDgJ6D8Y"}},{"cell_type":"markdown","source":["**Conclusion: cross_entropy function is numerically more behaved than direct calculation**"],"metadata":{"id":"tJPp9Oj46sc-"}},{"cell_type":"markdown","source":["**Meta-Exercise - Generating words using the trigram model we trained**"],"metadata":{"id":"X_W9v_vVFXmH"}},{"cell_type":"code","source":["# Once again the trigram model"],"metadata":{"id":"3SO5ytxIGgQg","executionInfo":{"status":"ok","timestamp":1718475170093,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["words = open('names.txt', 'r').read().splitlines()"],"metadata":{"id":"FbRktaUdSv50","executionInfo":{"status":"ok","timestamp":1718474997672,"user_tz":-330,"elapsed":532,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["chars = sorted(list(set(''.join(words))))"],"metadata":{"id":"ET5kSWFwF3tK","executionInfo":{"status":"ok","timestamp":1718475019657,"user_tz":-330,"elapsed":445,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["new_chars = ['.'] + chars\n","list_twos = []\n","for ch1 in new_chars:\n","  for ch2 in new_chars[1:]:\n","    list_twos.append(ch1+ch2)\n","list_twos.append('..')\n","pairs = sorted(list_twos)\n","len(pairs)\n","# pairs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4UC-rZ8AF9Hh","executionInfo":{"status":"ok","timestamp":1718475039109,"user_tz":-330,"elapsed":441,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"b9fbccd1-021b-4050-8721-1f11a3213f96"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["703"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["stoi_2 = {s:i for i, s in enumerate(pairs)}\n","itos_2 = {i:s for s, i in stoi_2.items()}\n","stoi_1 = {s:i for i, s in enumerate(new_chars)}\n","itos_1 = {i:s for s, i in stoi_1.items()}"],"metadata":{"id":"hfNnrH1iGBko","executionInfo":{"status":"ok","timestamp":1718475059196,"user_tz":-330,"elapsed":513,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch"],"metadata":{"id":"dbJ1CQWWGGcq","executionInfo":{"status":"ok","timestamp":1718475144177,"user_tz":-330,"elapsed":4303,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["N = torch.zeros((703, 27), dtype = torch.int32)"],"metadata":{"id":"mP9835YpGZzg","executionInfo":{"status":"ok","timestamp":1718475220812,"user_tz":-330,"elapsed":5,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["for w in words:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    N[indx1, indx2]+=1"],"metadata":{"id":"wk5qXWqnGa9N","executionInfo":{"status":"ok","timestamp":1718475230419,"user_tz":-330,"elapsed":9187,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["P = (N+1).float()\n","P/=P.sum(1, keepdims=True)"],"metadata":{"id":"p7Yjm8MCGfBQ","executionInfo":{"status":"ok","timestamp":1718475230420,"user_tz":-330,"elapsed":21,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["log_likelihood = 0.0\n","n = 0\n","\n","for w in words:\n","  chs = ['.'] + ['.'] + list(w) + ['.']\n","  for x, y, z in zip(chs, chs[1:], chs[2:]):\n","    xs = (x+y)\n","    ys = z\n","    # print(xs, ys)\n","    indx1 = stoi_2[xs]\n","    indx2 = stoi_1[ys]\n","    prob = P[indx1, indx2]\n","    logprob = torch.log(prob)\n","    log_likelihood += logprob\n","    n += 1\n","\n","nll = -log_likelihood\n","print(f'{nll/n}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6M2TC0FLGuhx","executionInfo":{"status":"ok","timestamp":1718475233023,"user_tz":-330,"elapsed":2621,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"833ea712-339e-4513-f3cc-a53e656a2e90"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2119739055633545\n"]}]},{"cell_type":"code","source":["g = torch.Generator().manual_seed(2147483647+10)\n","\n","for _ in range(30):\n","    out = []\n","    temp = [0, 0]\n","    while True:\n","        chs = itos_1[temp[0]] + itos_1[temp[1]]\n","        indx = stoi_2[chs]\n","        p = P[indx]\n","        indx_next = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n","        if indx_next==0:\n","            break\n","        temp = temp[1:] + [indx_next]\n","        out.append(itos_1[indx_next])\n","\n","    print(''.join(out))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7_X9-KobGvGL","executionInfo":{"status":"ok","timestamp":1718475539237,"user_tz":-330,"elapsed":706,"user":{"displayName":"Nakka Sai Deepthika","userId":"09422628091457802702"}},"outputId":"10e6d808-2f1c-4448-d24c-5f50e879fc9f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["mon\n","ammyan\n","see\n","madhriah\n","rethruthadraeg\n","aderedielin\n","shi\n","jen\n","edelieananarleilyn\n","hona\n","ca\n","shubvrgihimiel\n","kin\n","renelilanteromius\n","kavder\n","yahleyeh\n","yumajaystondrihil\n","salynnsuf\n","zakel\n","june\n","jart\n","kiveaosten\n","adi\n","fen\n","oloeh\n","zptin\n","samuezwhkhareon\n","is\n","kiri\n","evon\n"]}]}]}